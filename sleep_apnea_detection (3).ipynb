{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5kpDHfA3n72",
        "outputId": "ec9e9f3a-6f9a-4fb4-915e-0fa94eeddfbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL7p8Nkd36If",
        "outputId": "d2a4700e-8fa8-4383-84ec-0c8c35a71ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting biosppy\n",
            "  Downloading biosppy-2.2.3-py2.py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting peakutils\n",
            "  Downloading PeakUtils-1.3.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bidict (from biosppy)\n",
            "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from biosppy) (3.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from biosppy) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biosppy) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from biosppy) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from biosppy) (1.14.1)\n",
            "Collecting shortuuid (from biosppy)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from biosppy) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from biosppy) (1.4.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from biosppy) (4.11.0.86)\n",
            "Collecting pywavelets (from biosppy)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting mock (from biosppy)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.11.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.3.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->biosppy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->biosppy) (3.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Downloading biosppy-2.2.3-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.0/158.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PeakUtils-1.3.5-py3-none-any.whl (7.7 kB)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: shortuuid, pywavelets, mock, bidict, peakutils, pandas, wfdb, biosppy\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bidict-0.23.1 biosppy-2.2.3 mock-5.2.0 pandas-2.2.3 peakutils-1.3.5 pywavelets-1.8.0 shortuuid-1.0.13 wfdb-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install biosppy peakutils wfdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CuJqSec4IBd",
        "outputId": "d57186c3-9804-45ba-b952-4a1e78f1a138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.3\n",
            "    Uninstalling pandas-2.2.3:\n",
            "      Successfully uninstalled pandas-2.2.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "wfdb 4.3.0 requires pandas>=2.2.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==2.2.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSIDRbbL4bxM",
        "outputId": "03f24e4a-de8e-4a58-df7d-e59b3d1c4adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 184 (delta 32), reused 31 (delta 31), pack-reused 148 (from 1)\u001b[K\n",
            "Receiving objects: 100% (184/184), 1.28 MiB | 3.81 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "/content/Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/XianhuiChen/Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network.git\n",
        "%cd Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19hWQqtN4hnr"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "uploaded_zip_path = '/content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0.zip'  # <-- update if needed\n",
        "extract_to_path = '/content/drive/MyDrive/nndl'\n",
        "\n",
        "with ZipFile(uploaded_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEd-thi54pg_",
        "outputId": "5b1446ce-6497-44e6-c351-fa7bf78001b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0.zip\n",
            "replace /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x35.xws? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x35.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b04.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x24.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c06.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a05.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c07.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a18.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a08.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/additional-information.txt  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x24.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x30.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x31.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a07.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x07.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a05.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x02.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a16.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b02.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x23.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x06.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x18.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x03.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b05.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x11.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x28.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a14.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x32.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/SHA256SUMS.txt  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a06.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x26.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x30.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b02.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x31.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b04.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a05.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a15.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a07.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x16.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x13.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a07.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x16.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x06.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a13.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x30.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a13.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x26.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x20.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x11.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x34.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x13.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c05.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a07.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a14.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x05.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x09.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x03.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x33.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a11.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/RECORDS  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c06.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a20.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x17.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c08.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x34.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a13.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x35.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a11.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a19.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x10.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x10.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a16.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a12.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a11.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x01.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x32.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a19.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a16.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a14.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a16.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x12.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x10.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x05.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x15.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a19.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x04.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x23.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x29.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c07.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x29.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a06.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x34.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x07.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x22.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a14.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x34.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a08.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a15.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a09.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x05.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x20.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b03.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x15.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x01.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x12.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x07.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x32.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x25.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x03.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c09.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x21.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x21.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a09.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a12.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c07.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x23.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a19.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x27.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a05.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x29.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x03.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b05.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c08.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a12.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a07.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x21.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c10.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c04.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x12.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x26.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c05.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a17.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x01.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a16.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c08.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x20.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c09.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b05.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x14.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a17.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a17.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a17.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c04.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x28.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a06.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x21.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x22.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a20.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/ANNOTATORS  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c04.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x08.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x09.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a12.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a15.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a12.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x15.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c07.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x06.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x16.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x04.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a13.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c07.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x22.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b04.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x17.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a20.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x26.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c09.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x29.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a06.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x28.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a10.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c06.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x06.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a10.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x35.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a09.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x02.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x25.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c10.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c06.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a17.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x19.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x28.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a05.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b04.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a13.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x27.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x31.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a18.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a10.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x27.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c10.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c05.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a20.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x10.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c10.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x04.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b05.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x19.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x18.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b02.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c09.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a10.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a18.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a10.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a08.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x02.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x04.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x08.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c04.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b03.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x02.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x09.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x25.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/annotations.shtml  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a18.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x23.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c05.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x19.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b04.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a19.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x14.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x12.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c05.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x13.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x27.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x01.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b03.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x14.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x13.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c06.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c09.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x19.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x35.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x17.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x11.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x08.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x32.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c03.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c08.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a08.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b03.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/list  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x22.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b03.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x24.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04r.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a15.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x24.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01r.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x08.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b05.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x15.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x20.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x30.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a15.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x18.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x16.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a08.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x18.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a14.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01er.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c10.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x05.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c08.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a11.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b02.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x14.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a03.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x31.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a02r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x25.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a11.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c02er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01er.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x17.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x07.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a09.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04er.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a18.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x33.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a09.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a01er.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c04.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a04r.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/c01.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b01.apn  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x09.xws  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x11.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/b02.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x33.qrs  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a06.hea  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/x33.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/a20.dat  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/template-test-2  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/summary-training-1  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/template-test-1  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/template-training-2  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/summary-training-2  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/index.shtml  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/distill.c  \n",
            " extracting: /content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/challenge/template-training-1  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0.zip\" -d /content/drive/MyDrive/nndl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYKxkfEX4xFS"
      },
      "outputs": [],
      "source": [
        "!sed -i 's/from sklearn.utils import cpu_count/from multiprocessing import cpu_count/' /content/Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network/Preprocessing.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0vbMH565hTH",
        "outputId": "978cb8ad-712b-49cd-ad5b-145180545ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "a01: 100%|██████████| 489/489 [02:51<00:00,  2.84it/s]\n",
            "a02: 100%|██████████| 528/528 [03:19<00:00,  2.65it/s]\n",
            "a03: 100%|██████████| 519/519 [02:38<00:00,  3.28it/s]\n",
            "a04: 100%|██████████| 492/492 [01:20<00:00,  6.09it/s]\n",
            "a05: 100%|██████████| 454/454 [01:15<00:00,  6.01it/s]\n",
            "a06: 100%|██████████| 510/510 [01:34<00:00,  5.38it/s]\n",
            "a07: 100%|██████████| 511/511 [01:26<00:00,  5.90it/s]\n",
            "a08: 100%|██████████| 501/501 [01:25<00:00,  5.84it/s]\n",
            "a09: 100%|██████████| 495/495 [01:25<00:00,  5.76it/s]\n",
            "a10: 100%|██████████| 517/517 [01:29<00:00,  5.77it/s]\n",
            "a11: 100%|██████████| 466/466 [01:25<00:00,  5.47it/s]\n",
            "a12: 100%|██████████| 577/577 [01:38<00:00,  5.84it/s]\n",
            "a13: 100%|██████████| 495/495 [01:25<00:00,  5.81it/s]\n",
            "a14: 100%|██████████| 509/509 [01:28<00:00,  5.78it/s]\n",
            "a15: 100%|██████████| 510/510 [01:34<00:00,  5.41it/s]\n",
            "a16: 100%|██████████| 482/482 [01:22<00:00,  5.81it/s]\n",
            "a17: 100%|██████████| 485/485 [01:44<00:00,  4.66it/s]\n",
            "a18: 100%|██████████| 489/489 [01:21<00:00,  5.98it/s]\n",
            "a19: 100%|██████████| 502/502 [01:21<00:00,  6.15it/s]\n",
            "a20: 100%|██████████| 510/510 [01:32<00:00,  5.52it/s]\n",
            "b01: 100%|██████████| 487/487 [01:30<00:00,  5.40it/s]\n",
            "b02: 100%|██████████| 517/517 [01:30<00:00,  5.73it/s]\n",
            "b03: 100%|██████████| 441/441 [01:18<00:00,  5.65it/s]\n",
            "b04: 100%|██████████| 429/429 [01:13<00:00,  5.85it/s]\n",
            "b05: 100%|██████████| 433/433 [01:18<00:00,  5.51it/s]\n",
            "c01: 100%|██████████| 484/484 [01:21<00:00,  5.97it/s]\n",
            "c02: 100%|██████████| 502/502 [01:23<00:00,  5.99it/s]\n",
            "c03: 100%|██████████| 454/454 [01:16<00:00,  5.90it/s]\n",
            "c04: 100%|██████████| 482/482 [01:22<00:00,  5.86it/s]\n",
            "c05: 100%|██████████| 466/466 [01:22<00:00,  5.62it/s]\n",
            "c06: 100%|██████████| 468/468 [01:27<00:00,  5.37it/s]\n",
            "c07: 100%|██████████| 429/429 [01:16<00:00,  5.60it/s]\n",
            "c08: 100%|██████████| 513/513 [01:26<00:00,  5.92it/s]\n",
            "c09: 100%|██████████| 468/468 [01:17<00:00,  6.06it/s]\n",
            "c10: 100%|██████████| 431/431 [01:13<00:00,  5.84it/s]\n",
            "\n",
            "Testing...\n",
            "x01: 100%|██████████| 523/523 [01:28<00:00,  5.89it/s]\n",
            "x02: 100%|██████████| 469/469 [01:30<00:00,  5.20it/s]\n",
            "x03: 100%|██████████| 465/465 [01:27<00:00,  5.33it/s]\n",
            "x04: 100%|██████████| 482/482 [01:21<00:00,  5.95it/s]\n",
            "x05: 100%|██████████| 505/505 [01:26<00:00,  5.81it/s]\n",
            "x06: 100%|██████████| 450/450 [01:16<00:00,  5.91it/s]\n",
            "x07: 100%|██████████| 509/509 [01:22<00:00,  6.19it/s]\n",
            "x08: 100%|██████████| 517/517 [01:30<00:00,  5.69it/s]\n",
            "x09: 100%|██████████| 508/508 [01:33<00:00,  5.43it/s]\n",
            "x10: 100%|██████████| 510/510 [01:31<00:00,  5.58it/s]\n",
            "x11: 100%|██████████| 457/457 [01:18<00:00,  5.81it/s]\n",
            "x12: 100%|██████████| 527/527 [01:54<00:00,  4.59it/s]\n",
            "x13: 100%|██████████| 506/506 [01:34<00:00,  5.36it/s]\n",
            "x14: 100%|██████████| 490/490 [01:33<00:00,  5.21it/s]\n",
            "x15: 100%|██████████| 498/498 [01:34<00:00,  5.26it/s]\n",
            "x16: 100%|██████████| 515/515 [01:25<00:00,  6.03it/s]\n",
            "x17: 100%|██████████| 400/400 [01:05<00:00,  6.07it/s]\n",
            "x18: 100%|██████████| 459/459 [01:18<00:00,  5.86it/s]\n",
            "x19: 100%|██████████| 487/487 [01:23<00:00,  5.86it/s]\n",
            "x20: 100%|██████████| 513/513 [01:31<00:00,  5.60it/s]\n",
            "x21: 100%|██████████| 510/510 [01:27<00:00,  5.82it/s]\n",
            "x22: 100%|██████████| 482/482 [01:17<00:00,  6.25it/s]\n",
            "x23: 100%|██████████| 527/527 [01:33<00:00,  5.65it/s]\n",
            "x24: 100%|██████████| 429/429 [01:10<00:00,  6.11it/s]\n",
            "x25: 100%|██████████| 510/510 [01:29<00:00,  5.71it/s]\n",
            "x26: 100%|██████████| 520/520 [01:33<00:00,  5.55it/s]\n",
            "x27: 100%|██████████| 498/498 [01:33<00:00,  5.30it/s]\n",
            "x28: 100%|██████████| 495/495 [01:31<00:00,  5.39it/s]\n",
            "x29: 100%|██████████| 470/470 [01:18<00:00,  5.95it/s]\n",
            "x30: 100%|██████████| 511/511 [01:27<00:00,  5.86it/s]\n",
            "x31: 100%|██████████| 557/557 [01:38<00:00,  5.65it/s]\n",
            "x32: 100%|██████████| 538/538 [01:33<00:00,  5.73it/s]\n",
            "x33: 100%|██████████| 473/473 [01:23<00:00,  5.67it/s]\n",
            "x34: 100%|██████████| 475/475 [01:25<00:00,  5.54it/s]\n",
            "x35: 100%|██████████| 483/483 [01:17<00:00,  6.24it/s]\n",
            "\n",
            "ok!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import sys\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "import biosppy.signals.tools as st\n",
        "import numpy as np\n",
        "import os\n",
        "import wfdb\n",
        "from biosppy.signals.ecg import correct_rpeaks, hamilton_segmenter\n",
        "from scipy.signal import medfilt\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PhysioNet Apnea-ECG dataset\n",
        "# url: https://physionet.org/physiobank/database/apnea-ecg/\n",
        "base_dir = \"/content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0\"\n",
        "\n",
        "fs = 100\n",
        "sample = fs * 60  # 1 min's sample points\n",
        "\n",
        "before = 2  # forward interval (min)\n",
        "after = 2  # backward interval (min)\n",
        "hr_min = 20\n",
        "hr_max = 300\n",
        "\n",
        "num_worker = 35 if cpu_count() > 35 else cpu_count() - 1  # Setting according to the number of CPU cores\n",
        "\n",
        "\n",
        "def worker(name, labels):\n",
        "    X = []\n",
        "    y = []\n",
        "    groups = []\n",
        "    signals = wfdb.rdrecord(os.path.join(base_dir, name), channels=[0]).p_signal[:, 0]\n",
        "    for j in tqdm(range(len(labels)), desc=name, file=sys.stdout):\n",
        "        if j < before or \\\n",
        "                (j + 1 + after) > len(signals) / float(sample):\n",
        "            continue\n",
        "        signal = signals[int((j - before) * sample):int((j + 1 + after) * sample)]\n",
        "        signal, _, _ = st.filter_signal(signal, ftype='FIR', band='bandpass', order=int(0.3 * fs),\n",
        "                                        frequency=[3, 45], sampling_rate=fs)\n",
        "        # Find R peaks\n",
        "        rpeaks, = hamilton_segmenter(signal, sampling_rate=fs)\n",
        "        rpeaks, = correct_rpeaks(signal, rpeaks=rpeaks, sampling_rate=fs, tol=0.1)\n",
        "        if len(rpeaks) / (1 + after + before) < 40 or \\\n",
        "                len(rpeaks) / (1 + after + before) > 200:  # Remove abnormal R peaks signal\n",
        "            continue\n",
        "        # Extract RRI, Ampl signal\n",
        "        rri_tm, rri_signal = rpeaks[1:] / float(fs), np.diff(rpeaks) / float(fs)\n",
        "        rri_signal = medfilt(rri_signal, kernel_size=3)\n",
        "        ampl_tm, ampl_siganl = rpeaks / float(fs), signal[rpeaks]\n",
        "        hr = 60 / rri_signal\n",
        "        # Remove physiologically impossible HR signal\n",
        "        if np.all(np.logical_and(hr >= hr_min, hr <= hr_max)):\n",
        "            # Save extracted signal\n",
        "            X.append([(rri_tm, rri_signal), (ampl_tm, ampl_siganl)])\n",
        "            y.append(0. if labels[j] == 'N' else 1.)\n",
        "            groups.append(name)\n",
        "    return X, y, groups\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    apnea_ecg = {}\n",
        "\n",
        "    names = [\n",
        "        \"a01\", \"a02\", \"a03\", \"a04\", \"a05\", \"a06\", \"a07\", \"a08\", \"a09\", \"a10\",\n",
        "        \"a11\", \"a12\", \"a13\", \"a14\", \"a15\", \"a16\", \"a17\", \"a18\", \"a19\", \"a20\",\n",
        "        \"b01\", \"b02\", \"b03\", \"b04\", \"b05\",\n",
        "        \"c01\", \"c02\", \"c03\", \"c04\", \"c05\", \"c06\", \"c07\", \"c08\", \"c09\", \"c10\"\n",
        "    ]\n",
        "\n",
        "    o_train = []\n",
        "    y_train = []\n",
        "    groups_train = []\n",
        "    print('Training...')\n",
        "    with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
        "        task_list = []\n",
        "        for i in range(len(names)):\n",
        "            labels = wfdb.rdann(os.path.join(base_dir, names[i]), extension=\"apn\").symbol\n",
        "            task_list.append(executor.submit(worker, names[i], labels))\n",
        "\n",
        "        for task in as_completed(task_list):\n",
        "            X, y, groups = task.result()\n",
        "            o_train.extend(X)\n",
        "            y_train.extend(y)\n",
        "            groups_train.extend(groups)\n",
        "\n",
        "    print()\n",
        "\n",
        "    answers = {}\n",
        "    with open(os.path.join(base_dir, \"/content/Toward-Sleep-Apnea-Detection-with-Lightweight-Multi-scaled-Fusion-Network/dataset/event-2-answers\"), \"r\") as f:\n",
        "        for answer in f.read().split(\"\\n\\n\"):\n",
        "            answers[answer[:3]] = list(\"\".join(answer.split()[2::2]))\n",
        "\n",
        "    names = [\n",
        "        \"x01\", \"x02\", \"x03\", \"x04\", \"x05\", \"x06\", \"x07\", \"x08\", \"x09\", \"x10\",\n",
        "        \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\",\n",
        "        \"x21\", \"x22\", \"x23\", \"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x29\", \"x30\",\n",
        "        \"x31\", \"x32\", \"x33\", \"x34\", \"x35\"\n",
        "    ]\n",
        "\n",
        "    o_test = []\n",
        "    y_test = []\n",
        "    groups_test = []\n",
        "    print(\"Testing...\")\n",
        "    with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
        "        task_list = []\n",
        "        for i in range(len(names)):\n",
        "            labels = answers[names[i]]\n",
        "            task_list.append(executor.submit(worker, names[i], labels))\n",
        "\n",
        "        for task in as_completed(task_list):\n",
        "            X, y, groups = task.result()\n",
        "            o_test.extend(X)\n",
        "            y_test.extend(y)\n",
        "            groups_test.extend(groups)\n",
        "\n",
        "    apnea_ecg = dict(o_train=o_train, y_train=y_train, groups_train=groups_train, o_test=o_test, y_test=y_test,\n",
        "                     groups_test=groups_test)\n",
        "    with open(os.path.join(base_dir, \"apnea-ecg.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(apnea_ecg, f, protocol=2)\n",
        "\n",
        "    print(\"\\nok!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hibYhUiW5o-w",
        "outputId": "670bbdb5-b81c-427f-e93e-2c4f421df690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_shape (11696, 900, 2) (11696, 540, 2) (11696, 180, 2)\n",
            "Learning rate:  0.0010000000474974513\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5857 - loss: 1.0322\n",
            "Epoch 1: val_accuracy improved from -inf to 0.57909, saving model to /content/drive/MyDrive/nndl/weights.best (1)/weights.best.keras\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 291ms/step - accuracy: 0.5859 - loss: 1.0314 - val_accuracy: 0.5791 - val_loss: 0.8304 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.9040 - loss: 0.3178\n",
            "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 640ms/step\n",
            "acc: 0.9064620832103866, sn: 0.8600924499229584, sp: 0.935246293639407, f1: 0.8756765236489137\n"
          ]
        }
      ],
      "source": [
        "\"\"\"NOTES: Batch data is different each time in keras, which result in slight differences in results.\"\"\"\n",
        "import pickle\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from keras.layers import Dropout, MaxPooling1D, Reshape, multiply, Conv1D, GlobalAveragePooling1D, Dense\n",
        "from keras import Input, Model\n",
        "from keras.models import load_model\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from scipy.interpolate import splev, splrep\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import random\n",
        "\n",
        "base_dir = \"./dataset\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
        "ir = 3  # interpolate interval\n",
        "before = 2\n",
        "after = 2\n",
        "# normalize\n",
        "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
        "\n",
        "def load_data(path):\n",
        "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
        "    with open(os.path.join(base_dir, path), 'rb') as f:  # read preprocessing result\n",
        "        apnea_ecg = pickle.load(f)\n",
        "    x_train1,x_train2,x_train3 = [],[],[]\n",
        "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
        "    groups_train = apnea_ecg[\"groups_train\"]\n",
        "    for i in range(len(o_train)):\n",
        "        (rri_tm, rri_signal), (ampl_tm, ampl_siganl) = o_train[i]\n",
        "        # Curve interpolation\n",
        "        rri_interp_signal = splev(tm, splrep(rri_tm, scaler(rri_signal), k=3), ext=1)\n",
        "        ampl_interp_signal = splev(tm, splrep(ampl_tm, scaler(ampl_siganl), k=3), ext=1)\n",
        "        x_train1.append([rri_interp_signal, ampl_interp_signal])  # 5-minute-long segment\n",
        "        x_train2.append([rri_interp_signal[180:720], ampl_interp_signal[180:720]])  # 3-minute-long segment\n",
        "        x_train3.append([rri_interp_signal[360:540], ampl_interp_signal[360:540]])  # 1-minute-long segment\n",
        "    x_training1,x_training2,x_training3,y_training,groups_training = [],[],[],[],[]\n",
        "    x_val1,x_val2,x_val3,y_val,groups_val = [],[],[],[],[]\n",
        "\n",
        "    trainlist = random.sample(range(len(o_train)),int(len(o_train)*0.7))\n",
        "    num = [i for i in range(16709)]\n",
        "    vallist = set(num) - set(trainlist)\n",
        "    vallist = list(vallist)\n",
        "    for i in trainlist:\n",
        "        x_training1.append(x_train1[i])\n",
        "        x_training2.append(x_train2[i])\n",
        "        x_training3.append(x_train3[i])\n",
        "        y_training.append(y_train[i])\n",
        "        groups_training.append(groups_train[i])\n",
        "    for i in vallist:\n",
        "        x_val1.append(x_train1[i])\n",
        "        x_val2.append(x_train2[i])\n",
        "        x_val3.append(x_train3[i])\n",
        "        y_val.append(y_train[i])\n",
        "        groups_val.append(groups_train[i])\n",
        "    x_training1 = np.array(x_training1, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_training2 = np.array(x_training2, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_training3 = np.array(x_training3, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    y_training = np.array(y_training, dtype=\"float32\")\n",
        "    x_val1 = np.array(x_val1, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_val2 = np.array(x_val2, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_val3 = np.array(x_val3, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    y_val = np.array(y_val, dtype=\"float32\")\n",
        "    x_test1,x_test2,x_test3 = [],[],[]\n",
        "    o_test, y_test = apnea_ecg[\"o_test\"], apnea_ecg[\"y_test\"]\n",
        "    groups_test = apnea_ecg[\"groups_test\"]\n",
        "    for i in range(len(o_test)):\n",
        "        (rri_tm, rri_signal), (ampl_tm, ampl_siganl) = o_test[i]\n",
        "        # Curve interpolation\n",
        "        rri_interp_signal = splev(tm, splrep(rri_tm, scaler(rri_signal), k=3), ext=1)\n",
        "        ampl_interp_signal = splev(tm, splrep(ampl_tm, scaler(ampl_siganl), k=3), ext=1)\n",
        "        x_test1.append([rri_interp_signal, ampl_interp_signal])\n",
        "        x_test2.append([rri_interp_signal[180:720], ampl_interp_signal[180:720]])\n",
        "        x_test3.append([rri_interp_signal[360:540], ampl_interp_signal[360:540]])\n",
        "    x_test1 = np.array(x_test1, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_test2 = np.array(x_test2, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    x_test3 = np.array(x_test3, dtype=\"float32\").transpose((0, 2, 1))\n",
        "    y_test = np.array(y_test, dtype=\"float32\")\n",
        "\n",
        "    return x_training1, x_training2, x_training3, y_training, groups_training, x_val1, x_val2, \\\n",
        "           x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch > 70 and (epoch - 1) % 10 == 0:\n",
        "        lr *= 0.1\n",
        "    print(\"Learning rate: \", lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def create_model(input_a_shape, input_b_shape, input_c_shape, weight=1e-3):\n",
        "    # SA-CNN-3\n",
        "    input1 = Input(shape=input_a_shape)\n",
        "    x1 = Conv1D(16, kernel_size=11, strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(input1)\n",
        "    x1 = Conv1D(24, kernel_size=11, strides=2, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x1)\n",
        "    x1 = MaxPooling1D(pool_size=3, padding=\"same\")(x1)\n",
        "    x1 = Conv1D(32, kernel_size=11, strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x1)\n",
        "    x1 = MaxPooling1D(pool_size=5, padding=\"same\")(x1)\n",
        "\n",
        "    # SA-CNN-2\n",
        "    input2 = Input(shape=input_b_shape)\n",
        "    x2 = Conv1D(16, kernel_size=11, strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(input2)\n",
        "    x2 = Conv1D(24, kernel_size=11, strides=2, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x2)\n",
        "    x2 = MaxPooling1D(pool_size=3, padding=\"same\")(x2)\n",
        "    x2 = Conv1D(32, kernel_size=11, strides=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x2)\n",
        "\n",
        "    # SA-CNN-1\n",
        "    input3 = Input(shape=input_c_shape)\n",
        "    x3 = Conv1D(16, kernel_size=11, strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight))(input3)\n",
        "    x3 = Conv1D(24, kernel_size=11, strides=2, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x3)\n",
        "    x3 = MaxPooling1D(pool_size=3, padding=\"same\")(x3)\n",
        "    x3 = Conv1D(32, kernel_size=1, strides=1, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(1e-3), bias_regularizer=l2(weight))(x3)\n",
        "\n",
        "    # Channel-wise attention module\n",
        "    concat = keras.layers.concatenate([x1, x2, x3], name=\"Concat_Layer\", axis=-1)\n",
        "    squeeze = GlobalAveragePooling1D()(concat)\n",
        "    excitation = Dense(48, activation='relu')(squeeze)\n",
        "    excitation = Dense(96, activation='sigmoid')(excitation)\n",
        "    excitation = Reshape((1, 96))(excitation)\n",
        "    scale = multiply([concat, excitation])\n",
        "    x = GlobalAveragePooling1D()(scale)\n",
        "    dp = Dropout(0.5)(x)\n",
        "    outputs = Dense(2, activation='softmax', name=\"Output_Layer\")(dp)\n",
        "    model = Model(inputs=[input1, input2, input3], outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load_data\n",
        "    path = \"/content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/apnea-ecg.pkl\"\n",
        "    x_train1, x_train2, x_train3, y_train, groups_train, x_val1, x_val2,\\\n",
        "    x_val3, y_val, groups_val, x_test1, x_test2, x_test3, y_test, groups_test = load_data(path)\n",
        "    y_train = keras.utils.to_categorical(y_train, num_classes=2)  # Convert to two categories\n",
        "    y_val = keras.utils.to_categorical(y_val, num_classes=2)\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
        "    print('input_shape', x_train1.shape, x_train2.shape, x_train3.shape)\n",
        "\n",
        "    # training\n",
        "    model = create_model(x_train1.shape[1:], x_train2.shape[1:], x_train3.shape[1:])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    filepath = \"/content/drive/MyDrive/nndl/weights.best (1)/weights.best.keras\"\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    callbacks_list = [lr_scheduler, checkpoint]\n",
        "    history = model.fit([x_train1, x_train2, x_train3], y_train, batch_size=128, epochs=1,\n",
        "                        validation_data=([x_val1, x_val2, x_val3], y_val), callbacks=callbacks_list)\n",
        "\n",
        "    # test\n",
        "    filepath = '/content/drive/MyDrive/nndl/weights.best (1)/weights.best.hdf5'\n",
        "    model = load_model(filepath)\n",
        "    loss, accuracy = model.evaluate([x_test1, x_test2, x_test3], y_test)\n",
        "    # save prediction score\n",
        "    y_score = model.predict([x_test1, x_test2, x_test3])\n",
        "    output = pd.DataFrame({\"y_true\": y_test[:, 1], \"y_score\": y_score[:, 1], \"subject\": groups_test})\n",
        "    output.to_csv(\"/content/drive/MyDrive/nndl/SE-MSCNN.csv\", index=False)\n",
        "    y_true, y_pred = np.argmax(y_test, axis=-1), np.argmax(model.predict([x_test1, x_test2, x_test3], batch_size=1024, verbose=1), axis=-1)\n",
        "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
        "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
        "    acc, sn, sp = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP)\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    print(\"acc: {}, sn: {}, sp: {}, f1: {}\".format(acc, sn, sp, f1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzmhs9LkIebj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6407827f-1c80-46d9-a8ca-c4aa8e94a000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.7833, Sensitivity: 0.6145, Specificity: 0.8881, F1 Score: 0.6848\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.7432, Sensitivity: 0.5414, Specificity: 0.8685, F1 Score: 0.6176\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.interpolate import splev, splrep\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "\n",
        "base_dir = \"./dataset\"\n",
        "ir = 3\n",
        "before = 2\n",
        "after = 2\n",
        "\n",
        "# normalize\n",
        "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
        "\n",
        "def load_flattened_data(path):\n",
        "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
        "    with open(os.path.join(base_dir, path), 'rb') as f:\n",
        "        apnea_ecg = pickle.load(f)\n",
        "\n",
        "    def interpolate_features(o_data):\n",
        "        features = []\n",
        "        for (rri_tm, rri_signal), (ampl_tm, ampl_signal) in o_data:\n",
        "            rri_interp = splev(tm, splrep(rri_tm, scaler(rri_signal), k=3), ext=1)\n",
        "            ampl_interp = splev(tm, splrep(ampl_tm, scaler(ampl_signal), k=3), ext=1)\n",
        "            # Combine into one flat feature vector\n",
        "            combined = np.hstack((rri_interp, ampl_interp))\n",
        "            features.append(combined)\n",
        "        return np.array(features)\n",
        "\n",
        "    X_train = interpolate_features(apnea_ecg[\"o_train\"])\n",
        "    y_train = np.array(apnea_ecg[\"y_train\"])\n",
        "    X_test = interpolate_features(apnea_ecg[\"o_test\"])\n",
        "    y_test = np.array(apnea_ecg[\"y_test\"])\n",
        "    groups_test = apnea_ecg[\"groups_test\"]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, groups_test\n",
        "\n",
        "# Load data\n",
        "path = \"/content/drive/MyDrive/nndl/apnea-ecg-database-1.0.0/apnea-ecg.pkl\"\n",
        "X_train, y_train, X_test, y_test, groups_test = load_flattened_data(path)\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# --- SVM Classifier ---\n",
        "svm_model = SVC(kernel='rbf', probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_preds = svm_model.predict(X_test)\n",
        "svm_probs = svm_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# --- KNN Classifier ---\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_preds = knn_model.predict(X_test)\n",
        "knn_probs = knn_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred, y_probs, groups_test, save_path):\n",
        "    C = confusion_matrix(y_true, y_pred, labels=(1, 0))\n",
        "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
        "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "    sn = TP / (TP + FN)\n",
        "    sp = TN / (TN + FP)\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')\n",
        "\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"Accuracy: {acc:.4f}, Sensitivity: {sn:.4f}, Specificity: {sp:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Save CSV with scores\n",
        "    pd.DataFrame({\n",
        "        \"y_true\": y_true,\n",
        "        \"y_score\": y_probs,\n",
        "        \"subject\": groups_test\n",
        "    }).to_csv(save_path, index=False)\n",
        "\n",
        "# Evaluate and Save\n",
        "evaluate_model(\"SVM\", y_test, svm_preds, svm_probs, groups_test, \"/content/drive/MyDrive/nndl/SVM.csv\")\n",
        "evaluate_model(\"KNN\", y_test, knn_preds, knn_probs, groups_test, \"/content/drive/MyDrive/nndl/KNN.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bpgBt16quBer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "def evaluate_method(csv_path, model_name):\n",
        "    # Load test output\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df[\"y_pred\"] = df[\"y_score\"] > 0.5\n",
        "\n",
        "    # Group by subject, calculate apnea frequency per hour\n",
        "    df = df.groupby(\"subject\", group_keys=False).apply(lambda d: d[\"y_pred\"].mean() * 60)\n",
        "    df.name = model_name\n",
        "    return df\n",
        "\n",
        "# Load predictions from each model\n",
        "semscnn = evaluate_method(\"/content/drive/MyDrive/nndl/SE-MSCNN.csv\", \"SEMSCNN\")\n",
        "svm = evaluate_method(\"/content/drive/MyDrive/nndl/SVM.csv\", \"SVM\")\n",
        "knn = evaluate_method(\"/content/drive/MyDrive/nndl/KNN.csv\", \"KNN\")\n",
        "\n",
        "# Load original annotation summary\n",
        "original = []\n",
        "with open(\"/content/drive/MyDrive/nndl/additional-information.txt\", \"r\") as f:\n",
        "    for line in f:\n",
        "        rows = line.strip().split(\"\\t\")\n",
        "        if len(rows) == 12 and rows[0].startswith(\"x\"):\n",
        "            original.append([rows[0], float(rows[3]) / float(rows[1]) * 60])\n",
        "original = pd.DataFrame(original, columns=[\"subject\", \"original\"]).set_index(\"subject\")\n",
        "\n",
        "# Combine all predictions\n",
        "all_df = pd.concat([semscnn, svm, knn, original], axis=1)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(name):\n",
        "    model_scores = all_df[[name, \"original\"]].dropna()\n",
        "    corr_value = model_scores.corr().iloc[0, 1]\n",
        "    binarized = model_scores.applymap(lambda x: int(x > 5))\n",
        "    C = confusion_matrix(binarized[\"original\"], binarized[name], labels=(1, 0))\n",
        "    TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
        "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
        "    sn = TP / (TP + FN)\n",
        "    sp = TN / (TN + FP)\n",
        "    auc = roc_auc_score(model_scores[\"original\"] > 5, model_scores[name])\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(f\"Accuracy: {acc * 100:.2f}%\")\n",
        "    print(f\"Sensitivity: {sn * 100:.2f}%\")\n",
        "    print(f\"Specificity: {sp * 100:.2f}%\")\n",
        "    print(f\"AUC: {auc:.3f}\")\n",
        "    print(f\"Correlation: {corr_value:.3f}\")\n",
        "\n",
        "# Evaluate each model\n",
        "evaluate_model(\"SEMSCNN\")\n",
        "evaluate_model(\"SVM\")\n",
        "evaluate_model(\"KNN\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfbrlvvqFshV",
        "outputId": "cf68fe3d-ac49-488b-a7a4-50d399205eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SEMSCNN Results:\n",
            "Accuracy: 100.00%\n",
            "Sensitivity: 100.00%\n",
            "Specificity: 100.00%\n",
            "AUC: 1.000\n",
            "Correlation: 0.979\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 88.57%\n",
            "Sensitivity: 95.65%\n",
            "Specificity: 75.00%\n",
            "AUC: 0.928\n",
            "Correlation: 0.765\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 85.71%\n",
            "Sensitivity: 100.00%\n",
            "Specificity: 58.33%\n",
            "AUC: 0.978\n",
            "Correlation: 0.849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5425d0258311>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"subject\", group_keys=False).apply(lambda d: d[\"y_pred\"].mean() * 60)\n",
            "<ipython-input-7-5425d0258311>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"subject\", group_keys=False).apply(lambda d: d[\"y_pred\"].mean() * 60)\n",
            "<ipython-input-7-5425d0258311>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df = df.groupby(\"subject\", group_keys=False).apply(lambda d: d[\"y_pred\"].mean() * 60)\n",
            "<ipython-input-7-5425d0258311>:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  binarized = model_scores.applymap(lambda x: int(x > 5))\n",
            "<ipython-input-7-5425d0258311>:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  binarized = model_scores.applymap(lambda x: int(x > 5))\n",
            "<ipython-input-7-5425d0258311>:36: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  binarized = model_scores.applymap(lambda x: int(x > 5))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ET4GeUuYFu1e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}